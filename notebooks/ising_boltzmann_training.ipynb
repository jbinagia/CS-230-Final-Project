{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "1. implement Boltzmann reweighting so expectation is properly calculated \n",
    "2. implement training by energy and KL loss \n",
    "3. (minor) update architecture defined above to match that of Noe et al. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "import torch\n",
    "from torch import distributions\n",
    "from torch import nn\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.models.ising import IsingModel\n",
    "import project.networks.net as net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Ising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 165 µs, sys: 1 µs, total: 166 µs\n",
      "Wall time: 172 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = 0.0\n",
    "J = 0.8\n",
    "T = 1.0\n",
    "N = 8\n",
    "\n",
    "ising = IsingModel(h = h, J = J)\n",
    "x0 = ising.init_coords(N)\n",
    "\n",
    "ising.draw_config(x0)\n",
    "%time ising.energy(x0) # energy of a given configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training set\n",
    "We'd like to have a $m$ x $N$ matrix containing our training data where $m$ is the number of realizations of the system and $N$ is the number of features (i.e. the flattened dimensions of the system). For example, a training set with 1000 samples of the Ising Model for $N=8$ would be of size (1000, 64). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2 # as done in Noe et al. for the biwell potential \n",
    "flattened_size = N**2\n",
    "\n",
    "training_set = np.zeros((num_samples,flattened_size), dtype=np.float32)\n",
    "for i in range(num_samples):\n",
    "    training_set[i,:] = ising.init_coords(N).flatten() # generate random configuration \n",
    "training_set = torch.from_numpy(training_set) # convert to PyTorch tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, note that although we flatten our configurations for training, the flattening procedure can easily be reversed via the `rehsape()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1, -1, -1, -1, -1,  1, -1],\n",
       "       [ 1, -1, -1,  1,  1,  1, -1,  1],\n",
       "       [-1, -1,  1, -1, -1, -1,  1, -1],\n",
       "       [-1,  1,  1, -1, -1, -1, -1, -1],\n",
       "       [ 1,  1,  1, -1, -1,  1,  1,  1],\n",
       "       [-1, -1, -1,  1, -1, -1, -1, -1],\n",
       "       [ 1, -1, -1, -1,  1,  1, -1, -1],\n",
       "       [-1, -1,  1,  1, -1, -1,  1, -1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1, -1, -1, -1, -1,  1, -1],\n",
       "       [ 1, -1, -1,  1,  1,  1, -1,  1],\n",
       "       [-1, -1,  1, -1, -1, -1,  1, -1],\n",
       "       [-1,  1,  1, -1, -1, -1, -1, -1],\n",
       "       [ 1,  1,  1, -1, -1,  1,  1,  1],\n",
       "       [-1, -1, -1,  1, -1, -1, -1, -1],\n",
       "       [ 1, -1, -1, -1,  1,  1, -1, -1],\n",
       "       [-1, -1,  1,  1, -1, -1,  1, -1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x0).flatten().reshape((N,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boltzmann generator\n",
    "## Define network architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = lambda: nn.Sequential(nn.Linear(N**2, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, N**2), nn.Tanh()) # net s\n",
    "nett = lambda: nn.Sequential(nn.Linear(N**2, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, N**2)) # net t\n",
    "\n",
    "first_mask = np.array(np.concatenate((np.ones(round(N**2/2)), np.zeros(round(N**2/2)))))\n",
    "masks_np = np.stack((first_mask, np.flip(first_mask),first_mask,np.flip(first_mask),first_mask, np.flip(first_mask))) \n",
    "masks = torch.from_numpy(masks_np.astype(np.float32))\n",
    "\n",
    "prior = distributions.MultivariateNormal(torch.zeros(N**2), torch.eye(N**2))      # so we have a total of 3 neural blocks (see fig. 1 of boltzmann generators paper)\n",
    "network = net.RealNVP(nets, nett, masks, prior, x0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: loss = 6.261\n",
      "iter 100: loss = -167.543\n",
      "iter 200: loss = -182.051\n",
      "iter 300: loss = -184.378\n",
      "iter 400: loss = -185.296\n",
      "iter 500: loss = -185.979\n",
      "iter 600: loss = -186.482\n",
      "iter 700: loss = -186.857\n",
      "iter 800: loss = -187.186\n",
      "iter 900: loss = -187.526\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([p for p in network.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "for t in range(1000):    \n",
    "    loss = network.my_loss(batch = training_set)\n",
    "    \n",
    "    optimizer.zero_grad() # we need to set the gradients to zero before starting to do \n",
    "                          # backpropragation because PyTorch accumulates the gradients on \n",
    "                          # subsequent backward passes.\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if t % 100 == 0:\n",
    "        print('iter %s:' % t, 'loss = %.3f' % loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
